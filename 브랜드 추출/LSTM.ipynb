{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding:utf-8 -*-\n",
    "\n",
    "import pickle\n",
    "with open('product_tokens.txt', 'rb') as f:\n",
    "    product_tokens = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['265', 'mm', '나이키', '인터내셔널', '리스트', '운동화', 'n', '26', '1', 'p']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "product_tokens[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['▁265', 'mm', '▁나이키', '▁인터내셔널', '▁리스트', '▁운동화', '▁n', '26', '1', 'p']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# -*- coding:utf-8 -*-\n",
    "\n",
    "import pickle\n",
    "with open('product_names.txt', 'rb') as f:\n",
    "    product_names = pickle.load(f)\n",
    "\n",
    "product_names[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from itertools import chain\n",
    "from nltk import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def labeling(label, tokens):\n",
    "    return [(word, label) for word in tokens]\n",
    "\n",
    "def branding(brand, tokens):\n",
    "    if brand in tokens:\n",
    "        br_idx = tokens.index(brand)\n",
    "        return labeling('0', tokens[:br_idx]) + labeling('BRAND', [tokens[br_idx]]) + labeling('0', tokens[br_idx+1:])\n",
    "    else:\n",
    "        return labeling('0', tokens)\n",
    "\n",
    "def one_hot_encoding(x, y):\n",
    "    y = np.array(y)\n",
    "    max_sentence_len = max(map(len, x))\n",
    "    all_tags = set(chain(*y))\n",
    "    NUM_TAGS = len(all_tags)\n",
    "    TAGS_MAP = {\"0\": 0, \"BRAND\": 1, \"NIL\": 2}\n",
    "    y = list(map(lambda x: [TAGS_MAP[t] for t in x], y))\n",
    "    y = pad_sequences(y, max_sentence_len, padding='pre')\n",
    "    y = np.array([to_categorical(t, NUM_TAGS) for t in y])\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>brand</th>\n",
       "      <th>preprocessed</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>99566976</td>\n",
       "      <td>265mm 나이키 인터내셔널 리스트 운동화 / N261P</td>\n",
       "      <td>나이키</td>\n",
       "      <td>265mm 나이키 인터내셔널 리스트 운동화 n261p</td>\n",
       "      <td>['265', 'mm', '나이키', '인터내셔널', '리스트', '운동화', 'n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100268480</td>\n",
       "      <td>☀️나이키 후드트레이닝세트☀️</td>\n",
       "      <td>나이키</td>\n",
       "      <td>나이키 후드트레이닝세트</td>\n",
       "      <td>['나이키', '후드', '트레이닝세트']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>888258</td>\n",
       "      <td>나이키 여성운동화 240</td>\n",
       "      <td>나이키</td>\n",
       "      <td>나이키 여성운동화 240</td>\n",
       "      <td>['나이키', '여성운동화', '240']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>99987072</td>\n",
       "      <td>나이키 셀렉트 팬츠 구매합니다</td>\n",
       "      <td>나이키</td>\n",
       "      <td>나이키 셀렉트 팬츠 구매합니다</td>\n",
       "      <td>['나이키', '', '셀렉트', '팬츠', '구매합니다']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>745734</td>\n",
       "      <td>급처나이키 크로스백팩</td>\n",
       "      <td>나이키</td>\n",
       "      <td>급처나이키 크로스백팩</td>\n",
       "      <td>['급처', '나이키', '크로스백', '팩']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id                             name brand  \\\n",
       "0   99566976  265mm 나이키 인터내셔널 리스트 운동화 / N261P   나이키   \n",
       "1  100268480                 ☀️나이키 후드트레이닝세트☀️   나이키   \n",
       "2     888258                    나이키 여성운동화 240   나이키   \n",
       "3   99987072                 나이키 셀렉트 팬츠 구매합니다   나이키   \n",
       "4     745734                      급처나이키 크로스백팩   나이키   \n",
       "\n",
       "                    preprocessed  \\\n",
       "0  265mm 나이키 인터내셔널 리스트 운동화 n261p   \n",
       "1                   나이키 후드트레이닝세트   \n",
       "2                  나이키 여성운동화 240   \n",
       "3               나이키 셀렉트 팬츠 구매합니다   \n",
       "4                    급처나이키 크로스백팩   \n",
       "\n",
       "                                              tokens  \n",
       "0  ['265', 'mm', '나이키', '인터내셔널', '리스트', '운동화', 'n...  \n",
       "1                            ['나이키', '후드', '트레이닝세트']  \n",
       "2                            ['나이키', '여성운동화', '240']  \n",
       "3                  ['나이키', '', '셀렉트', '팬츠', '구매합니다']  \n",
       "4                         ['급처', '나이키', '크로스백', '팩']  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['branding'] = [branding(brand, tokens) for brand, tokens in zip(df.brand, product_names)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_w, raw_t, raw_data = [], [], []\n",
    "for i in df['branding']:\n",
    "    for word, tag in i:\n",
    "        raw_w.append(word)\n",
    "        raw_t.append(tag)\n",
    "    raw_data.append((tuple(raw_w), tuple(raw_t)))\n",
    "    raw_w, raw_t = [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(('▁265', 'mm', '▁나이키', '▁인터내셔널', '▁리스트', '▁운동화', '▁n', '26', '1', 'p'),\n",
       " ('0', '0', '0', '0', '0', '0', '0', '0', '0', '0'))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sentencepiece as sp\n",
    "\n",
    "model_file = 'name_unigram_20000.model'\n",
    "sp_processor = sp.SentencePieceProcessor(model_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_x, all_y = [], []\n",
    "max_sentence_len = 100\n",
    "for words, tags in raw_data:\n",
    "    encoded_words, encoded_tags = [], []\n",
    "    for w, t in zip(words, tags):\n",
    "        if sp_processor.encode(w):\n",
    "            encoded_words.append(sp_processor.encode(w)[0])\n",
    "            encoded_tags.append(t)\n",
    "        else:\n",
    "            encoded_words.append(np.ones(20000))\n",
    "            encoded_tags.append(t)\n",
    "    \n",
    "    nil_x = np.zeros(20000)\n",
    "    nil_y = 'NIL'\n",
    "    pad_length = max_sentence_len - len(encoded_words)\n",
    "    all_x.append((pad_length*[nil_x]) + encoded_words)\n",
    "    all_y.append((pad_length*[nil_y]) + encoded_tags)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['NIL',\n",
       " 'NIL',\n",
       " 'NIL',\n",
       " 'NIL',\n",
       " 'NIL',\n",
       " 'NIL',\n",
       " 'NIL',\n",
       " 'NIL',\n",
       " 'NIL',\n",
       " 'NIL',\n",
       " 'NIL',\n",
       " 'NIL',\n",
       " 'NIL',\n",
       " 'NIL',\n",
       " 'NIL',\n",
       " 'NIL',\n",
       " 'NIL',\n",
       " 'NIL',\n",
       " 'NIL',\n",
       " 'NIL',\n",
       " 'NIL',\n",
       " 'NIL',\n",
       " 'NIL',\n",
       " 'NIL',\n",
       " 'NIL',\n",
       " 'NIL',\n",
       " 'NIL',\n",
       " 'NIL',\n",
       " 'NIL',\n",
       " 'NIL',\n",
       " 'NIL',\n",
       " 'NIL',\n",
       " 'NIL',\n",
       " 'NIL',\n",
       " 'NIL',\n",
       " 'NIL',\n",
       " 'NIL',\n",
       " 'NIL',\n",
       " 'NIL',\n",
       " 'NIL',\n",
       " 'NIL',\n",
       " 'NIL',\n",
       " 'NIL',\n",
       " 'NIL',\n",
       " 'NIL',\n",
       " 'NIL',\n",
       " 'NIL',\n",
       " 'NIL',\n",
       " 'NIL',\n",
       " 'NIL',\n",
       " 'NIL',\n",
       " 'NIL',\n",
       " 'NIL',\n",
       " 'NIL',\n",
       " 'NIL',\n",
       " 'NIL',\n",
       " 'NIL',\n",
       " 'NIL',\n",
       " 'NIL',\n",
       " 'NIL',\n",
       " 'NIL',\n",
       " 'NIL',\n",
       " 'NIL',\n",
       " 'NIL',\n",
       " 'NIL',\n",
       " 'NIL',\n",
       " 'NIL',\n",
       " 'NIL',\n",
       " 'NIL',\n",
       " 'NIL',\n",
       " 'NIL',\n",
       " 'NIL',\n",
       " 'NIL',\n",
       " 'NIL',\n",
       " 'NIL',\n",
       " 'NIL',\n",
       " 'NIL',\n",
       " 'NIL',\n",
       " 'NIL',\n",
       " 'NIL',\n",
       " 'NIL',\n",
       " 'NIL',\n",
       " 'NIL',\n",
       " 'NIL',\n",
       " 'NIL',\n",
       " 'NIL',\n",
       " 'NIL',\n",
       " 'NIL',\n",
       " 'NIL',\n",
       " 'NIL',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0']"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_x, all_y = [], []\n",
    "max_sentence_len = 36\n",
    "for words, tags in raw_data:\n",
    "    encoded_words, encoded_tags = [], []\n",
    "    for w, t in zip(words, tags):\n",
    "        if w.lower() in word_to_idx:\n",
    "            encoded_words.append(word_to_idx[w.lower()])\n",
    "            encoded_tags.append(t)\n",
    "        else:\n",
    "            encoded_words.append(np.ones(50))\n",
    "            encoded_tags.append(t)\n",
    "\n",
    "    nil_x = np.zeros(50)\n",
    "    nil_y = 'NIL'\n",
    "    pad_length = max_sentence_len - len(encoded_words)\n",
    "    all_x.append((pad_length * [nil_x]) + encoded_words)\n",
    "    all_y.append((pad_length * [nil_y]) + encoded_tags)\n",
    "all_x, all_y = one_hot_encoding(all_x, all_y)\n",
    "all_x, all_y = np.array(all_x), np.array(all_y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
